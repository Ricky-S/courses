{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 9)\n"
     ]
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('concrete_data.csv')\n",
    "print(concrete_data.shape)\n",
    "# concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether the data clean?\n",
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Build a baseline model (5 marks)\n",
    "\n",
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error as the loss function.\n",
    "\n",
    "\n",
    "+1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_splithelper function from Scikit-learn.\n",
    "\n",
    "+2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "+3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "+4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "+5. Report the mean and the standard deviation of the mean squared errors.\n",
    "\n",
    "Submit your Jupyter Notebook with your code and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error 1: 266.61281015340563\n",
      "mean_squared_error 8: 74.88624582630145\n",
      "mean_squared_error 15: 45.97379730125847\n",
      "mean_squared_error 22: 53.91559714406825\n",
      "mean_squared_error 29: 44.67223105075676\n",
      "mean_squared_error 36: 43.89444874636949\n",
      "mean_squared_error 43: 49.69320925616909\n",
      "mean_squared_error 50: 49.269314392484894\n",
      "------\n",
      "report the mean and the standard deviation of the mean squared errors:\n",
      "mean of the mean squared errors:   63.08201760589953\n",
      "Standard Deviation of the mean squared errors: 41.28716475693235\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors_A = []\n",
    "model_A = Sequential()\n",
    "model_A.add(Dense(10, activation='relu', input_shape=(8,)))\n",
    "model_A.add(Dense(1))\n",
    "model_A.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3)\n",
    "    model_A.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    MSE = model_A.evaluate(X_test, y_test, verbose=0)\n",
    "    if i%7==0:\n",
    "        print(\"mean_squared_error \"+str(i+1)+\": \"+str(MSE))\n",
    "    y_pred = model_A.predict(X_test)\n",
    "    mean_squared_error1 = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors_A.append(mean_squared_error1)\n",
    "\n",
    "mean_squared_errors_A = np.array(mean_squared_errors_A)\n",
    "standard_deviation_A = np.std(mean_squared_errors_A)\n",
    "\n",
    "print('------')\n",
    "print('report the mean and the standard deviation of the mean squared errors:')\n",
    "print(\"mean of the mean squared errors:   \"+str(np.mean(mean_squared_errors_A)))\n",
    "print(\"Standard Deviation of the mean squared errors: \"+str(standard_deviation_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Normalize the data (5 marks)\n",
    "\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error 1: 256.1519864276775\n",
      "mean_squared_error 8: 52.62734868071226\n",
      "mean_squared_error 15: 46.41972041207224\n",
      "mean_squared_error 22: 44.635307324357015\n",
      "mean_squared_error 29: 38.92301518708757\n",
      "mean_squared_error 36: 46.695280525676644\n",
      "mean_squared_error 43: 40.96458712210547\n",
      "mean_squared_error 50: 45.33393547527227\n",
      "------\n",
      "report the mean and the standard deviation of the mean squared errors:\n",
      "mean of the mean squared errors:   54.58903810898684\n",
      "Standard Deviation of the mean squared errors: 34.517456829092886\n"
     ]
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "mean_squared_errors_B = []\n",
    "model_B = Sequential()\n",
    "model_B.add(Dense(10, activation='relu', input_shape=(8,)))\n",
    "model_B.add(Dense(1))\n",
    "model_B.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    model_B.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    MSE = model_B.evaluate(X_test, y_test, verbose=0)\n",
    "    if i%7==0:\n",
    "        print(\"mean_squared_error \"+str(i+1)+\": \"+str(MSE))\n",
    "    y_pred = model_B.predict(X_test)\n",
    "    mean_squared_error1 = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors_B.append(mean_squared_error1)\n",
    "\n",
    "mean_squared_errors_B = np.array(mean_squared_errors_B)\n",
    "standard_deviation_B = np.std(mean_squared_errors_B)\n",
    "\n",
    "print('------')\n",
    "print('report the mean and the standard deviation of the mean squared errors:')\n",
    "print(\"mean of the mean squared errors:   \"+str(np.mean(mean_squared_errors_B)))\n",
    "print(\"Standard Deviation of the mean squared errors: \"+str(standard_deviation_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis\n",
    "we can see that mean and standard deviation of B is better than A because B is using norm data.\n",
    "\n",
    "if we want to improve the model. Norm the data is a good way to consider.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Increate the number of epochs (5 marks)\n",
    "\n",
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error 1: 152.30373091219312\n",
      "mean_squared_error 8: 61.33376620271059\n",
      "mean_squared_error 15: 40.957772177785735\n",
      "mean_squared_error 22: 32.66048418433921\n",
      "mean_squared_error 29: 33.19966727321588\n",
      "mean_squared_error 36: 31.37399288288598\n",
      "mean_squared_error 43: 31.19504623042727\n",
      "mean_squared_error 50: 33.63817639644092\n",
      "------\n",
      "report the mean and the standard deviation of the mean squared errors:\n",
      "mean of the mean squared errors:   46.029801159354776\n",
      "Standard Deviation of the mean squared errors: 22.46875594104405\n"
     ]
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "mean_squared_errors_C = []\n",
    "model_C = Sequential()\n",
    "model_C.add(Dense(10, activation='relu', input_shape=(8,)))\n",
    "model_C.add(Dense(1))\n",
    "model_C.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    model_C.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    MSE = model_C.evaluate(X_test, y_test, verbose=0)\n",
    "    if i%7==0:\n",
    "        print(\"mean_squared_error \"+str(i+1)+\": \"+str(MSE))\n",
    "    y_pred = model_C.predict(X_test)\n",
    "    mean_squared_error1 = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors_C.append(mean_squared_error1)\n",
    "\n",
    "mean_squared_errors_C = np.array(mean_squared_errors_C)\n",
    "standard_deviation_C = np.std(mean_squared_errors_C)\n",
    "\n",
    "print('------')\n",
    "print('report the mean and the standard deviation of the mean squared errors:')\n",
    "print(\"mean of the mean squared errors:   \"+str(np.mean(mean_squared_errors_C)))\n",
    "print(\"Standard Deviation of the mean squared errors: \"+str(standard_deviation_C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis\n",
    "we can see that mean and standard deviation of C is better than B because C has more epochs.\n",
    "\n",
    "if we want to improve the model. adding more epochs is a good way to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Increase the number of hidden layers (5 marks)\n",
    "\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error 1: 129.23419461049693\n",
      "mean_squared_error 8: 33.44898904102906\n",
      "mean_squared_error 15: 31.488226745506708\n",
      "mean_squared_error 22: 29.599865576981728\n",
      "mean_squared_error 29: 24.603058916851154\n",
      "mean_squared_error 36: 22.589288816482888\n",
      "mean_squared_error 43: 23.855510699324622\n",
      "mean_squared_error 50: 18.39867287237667\n",
      "------\n",
      "report the mean and the standard deviation of the mean squared errors:\n",
      "mean of the mean squared errors:   30.712762870146022\n",
      "Standard Deviation of the mean squared errors: 16.84334858573611\n"
     ]
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "mean_squared_errors_D = []\n",
    "model_D = Sequential()\n",
    "model_D.add(Dense(10, activation='relu', input_shape=(8,)))\n",
    "model_D.add(Dense(10, activation='relu'))\n",
    "model_D.add(Dense(10, activation='relu'))\n",
    "model_D.add(Dense(1))\n",
    "model_D.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "for i in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    model_D.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    MSE = model_D.evaluate(X_test, y_test, verbose=0)\n",
    "    if i%7==0:\n",
    "        print(\"mean_squared_error \"+str(i+1)+\": \"+str(MSE))\n",
    "    y_pred = model_D.predict(X_test)\n",
    "    mean_squared_error_D = mean_squared_error(y_test, y_pred)\n",
    "    mean_squared_errors_D.append(mean_squared_error_D)\n",
    "\n",
    "mean_squared_errors_D = np.array(mean_squared_errors_D)\n",
    "standard_deviation_D = np.std(mean_squared_errors_D)\n",
    "\n",
    "print('------')\n",
    "print('report the mean and the standard deviation of the mean squared errors:')\n",
    "print(\"mean of the mean squared errors:   \"+str(np.mean(mean_squared_errors_D)))\n",
    "print(\"Standard Deviation of the mean squared errors: \"+str(standard_deviation_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis\n",
    "we can see that mean and standard deviation of D is better than B because D has more hidden layers.\n",
    "\n",
    "if we want to improve the model. adding more hidden layers is a good way to consider.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>63.08201760589953</td>\n",
       "      <td>41.287165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>54.58903810898684</td>\n",
       "      <td>34.517457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>46.029801159354776</td>\n",
       "      <td>22.468756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>30.712762870146022</td>\n",
       "      <td>16.843349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                Mean  Standard Deviation\n",
       "0  A   63.08201760589953           41.287165\n",
       "1  B   54.58903810898684           34.517457\n",
       "2  C  46.029801159354776           22.468756\n",
       "3  D  30.712762870146022           16.843349"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"id\":[\"A\",'B','C','D'], \n",
    " \"Mean\":[str(np.mean(mean_squared_errors_A)),str(np.mean(mean_squared_errors_B)),\n",
    "                                                str(np.mean(mean_squared_errors_C)),str(np.mean(mean_squared_errors_D))],\n",
    "  \"Standard Deviation\":[standard_deviation_A, standard_deviation_B,standard_deviation_C,standard_deviation_D]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
